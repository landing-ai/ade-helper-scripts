{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdd1b88",
   "metadata": {},
   "source": [
    "# Agentic Document Extraction with Snowflake Insertion\n",
    "\n",
    "This notebook demonstrates a **complete pipeline** for parsing documents using [Agentic Document Extraction (ADE)](https://docs.landing.ai/ade/ade-overview) and inserting structured results into **Snowflake**.\n",
    "\n",
    "You‚Äôll learn how to:\n",
    "\n",
    "1) Parse documents into machine-readable markdown and JSON with **maximal parallelism**.\n",
    "2) Extract structured fields from documents using LandingAI's Agentic Document Extraction (ADE) service.\n",
    "3) Insert both:\n",
    "   - the **original document** into a Snowflake external stage,\n",
    "   - and the **extracted data** into multiple Snowflake tables.\n",
    "4) Use a **buffered, shard-based insertion approach** for scalable loading.\n",
    "\n",
    "> This notebook focuses on **invoice extraction**, but the pattern is modular and can be adapted to **any document type**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Title: Agentic Document Extraction with Snowflake Insertion\n",
    "# Author: Andrea Kropp\n",
    "# Description: This notebook demonstrates a modular pipeline using Agentic Document Extraction (ADE) to parse invoices and stream structured results into Snowflake. \n",
    "# Target Audience: Developers, Snowflake Partners\n",
    "# Content Type: Workflow Tutorial\n",
    "# Publish Date: 2025-09-07\n",
    "# ADE Version: v0.3.1\n",
    "# Change Log:\n",
    "#    - v1.0: Initial draft\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1cbee",
   "metadata": {},
   "source": [
    "## üìÅ Project Structure\n",
    "\n",
    "The pipeline is modular and lives in reusable Python modules:\n",
    "\n",
    "```bash\n",
    "project/\n",
    "‚îú‚îÄ‚îÄ ade_sf_pipeline_main.py   # üîÅ Main orchestration: parse ‚Üí transform ‚Üí stage ‚Üí insert\n",
    "‚îú‚îÄ‚îÄ config.py                 # ‚öôÔ∏è  Centralized settings (from .env or environment variables)\n",
    "‚îú‚îÄ‚îÄ sf_utils.py               # üßä Snowflake utilities: connect, stage/table naming, DDL setup\n",
    "‚îú‚îÄ‚îÄ doc_utils.py              # üìÑ Document utilities: page counting, helpers for metadata\n",
    "‚îú‚îÄ‚îÄ metrics.py                # ‚è±Ô∏è  Track wall time, parse latency, total pages, OK/FAIL count\n",
    "‚îú‚îÄ‚îÄ version_utils.py          # üì¶ Resolve installed ADE package version\n",
    "‚îú‚îÄ‚îÄ row_builder.py            # üß± Build output rows from parsed documents (custom per schema)\n",
    "‚îú‚îÄ‚îÄ loader.py                 # üì§ Buffered uploader, handles local ‚Üí stage ‚Üí Snowflake COPY\n",
    "‚îú‚îÄ‚îÄ invoice_schema.py         # üìë Defines Pydantic schema of fields to extract (custom per use case)\n",
    "‚îú‚îÄ‚îÄ row_utils.py              # üîß Shared helpers for row construction (type coercion, dig, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2704c24",
   "metadata": {},
   "source": [
    "### üß© What You Need to Provide\n",
    "\n",
    "To adapt this pipeline for your specific document type, you only need to supply three components:\n",
    "\n",
    "1. ‚úÖ **Pydantic Schema Definition**  \n",
    "   Define a schema class (e.g., `InvoiceExtractionSchema`) in `invoice_schema.py` that specifies the fields to extract from your documents using ADE.\n",
    "\n",
    "2. ‚úÖ **Row Builder Adapter**  \n",
    "   Implement a `rows_from_doc()` function in `row_builder.py` that maps a parsed document to structured rows for each target Snowflake table (e.g., main, line items, chunks, markdown).\n",
    "\n",
    "3. ‚úÖ **Snowflake Column Lists**  \n",
    "   Provide column lists (`COLS_MAIN`, `COLS_LINES`, etc.) that align exactly with your Snowflake table definitions.\n",
    "\n",
    "> üìÅ **Only modify:** `invoice_schema.py`, `row_builder.py`, and optionally `loader.py`  \n",
    "These are the only files you need to adapt when working with a new document type or use case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e8e55",
   "metadata": {},
   "source": [
    "## üîß Configuration and Imports\n",
    "\n",
    "This section loads the required modules for:\n",
    "\n",
    "- Parsing documents with Agentic Document Extrcation from LandingAI\n",
    "- Configuring and connecting to Snowflake\n",
    "- Uploading extracted results via `Loader`\n",
    "- Tracking wall-clock and parse time via `Metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c68ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:13:51\u001b[0m [info   \u001b[0m] \u001b[1mSettings loaded: {\n",
      "  \"endpoint_host\": \"https://api.va.landing.ai\",\n",
      "  \"vision_agent_api_key\": \"OTBiN[REDACTED]\",\n",
      "  \"batch_size\": 50,\n",
      "  \"max_workers\": 2,\n",
      "  \"max_retries\": 5,\n",
      "  \"max_retry_wait_time\": 30,\n",
      "  \"retry_logging_style\": \"log_msg\",\n",
      "  \"pdf_to_image_dpi\": 96,\n",
      "  \"split_size\": 10,\n",
      "  \"extraction_split_size\": 50\n",
      "}\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.config\u001b[0m]\u001b[0m (config.py:170)\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os, uuid\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from pprint import pprint\n",
    "\n",
    "# Agentic Document Extraction from LandingAI\n",
    "from agentic_doc.parse import parse\n",
    "\n",
    "# Configuration & settings management (pydantic)\n",
    "from config import Settings\n",
    "\n",
    "# Snowflake utilities: table naming, setup, SQL execution\n",
    "from sf_utils import ensure_formats_and_stages, sfcursor, fq_table, put_original_to_raw_stage\n",
    "\n",
    "# Basic utilities: page counting and reproducibility\n",
    "from doc_utils import get_doc_pages\n",
    "from version_utils import get_installed_version\n",
    "\n",
    "# Core logic: row transformation from parsed doc\n",
    "from row_builder import rows_from_doc\n",
    "\n",
    "# CSV buffering and Snowflake loader class\n",
    "from loader import Loader, COLS_MAIN, COLS_LINES\n",
    "\n",
    "# High-level pipeline orchestration\n",
    "from ade_sf_pipeline_main import run_pipeline_streaming\n",
    "\n",
    "# Custom schema for invoice processing\n",
    "from invoice_schema import InvoiceExtractionSchema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04541b",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Settings & Environment Variables\n",
    "\n",
    "This notebook has an accompying `.env` file which follows the example provided under [Configuration Options](https://docs.landing.ai/ade/ade-retries#configuration-options) in the documentation. All other required setting are in the class Setting in the `.config.py` file. Review the comments in the `.config` file to learn how these settings interact with `.env` settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8277b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 50,\n",
      " 'MAX_RETRIES': 5,\n",
      " 'MAX_RETRY_WAIT_TIME': 30,\n",
      " 'MAX_WORKERS': 2,\n",
      " 'RETRY_LOGGING_STYLE': 'log_msg',\n",
      " 'copy_after_files': 8,\n",
      " 'csv_file_format_name': 'CSV_STD',\n",
      " 'database': 'DEMOS_ADE_FINANCE',\n",
      " 'file_exts': {'.png', '.jpg', '.pdf', '.jpeg'},\n",
      " 'json_file_format_name': 'JSON_STD',\n",
      " 'max_rows_per_file': 5000,\n",
      " 'max_sec_per_file': 3.0,\n",
      " 'max_threads': 16,\n",
      " 'private_key_file': '/Users/andreakropp/secure_keys/rsa_key.p8',\n",
      " 'role': 'ADE_DEMOS',\n",
      " 'snowflake_account_identifier': 'RPWERKO-LAI_SNOW_SALES',\n",
      " 'snowflake_schema': 'INVOICES',\n",
      " 'snowflake_user': 'MACHINE_USER_2',\n",
      " 'stage_ingest_name': 'INGEST_TMP',\n",
      " 'stage_raw_name': 'PARSED_INVOICES_COMPLETED',\n",
      " 'table_chunks': 'PARSED_CHUNKS',\n",
      " 'table_lines': 'INVOICE_LINE_ITEMS',\n",
      " 'table_main': 'INVOICES_MAIN',\n",
      " 'table_markdown': 'MARKDOWN',\n",
      " 'warehouse': 'SNOWFLAKE_TUTORIALS'}\n"
     ]
    }
   ],
   "source": [
    "# Load configuration (from .env or environment variables)\n",
    "S = Settings()\n",
    "\n",
    "# Display resolved settings (for verification)\n",
    "pprint(S.model_dump(exclude={\"VISION_AGENT_API_KEY\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b3ea8",
   "metadata": {},
   "source": [
    "## Ensure Required Snowflake Formats and Stages Exist\n",
    "\n",
    "This step checks that the necessary tables, internal stages and file formats exist in your Snowflake account. If they don't, it creates them using standard options defined in `sf_utils.py`.\n",
    "\n",
    "We suggest **creating these manually from inside Snowflake**. See the `.sql` file that accompanies this notebook. You will need to give the snowflake_user specified in Settings a Snowflake Role which has the correct permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985ebc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Connector for Python Version: 3.17.2, Python Version: 3.12.11, Platform: macOS-15.5-arm64-arm-64bit (connection.py:521)\n",
      "Connecting to GLOBAL Snowflake domain (connection.py:1464)\n",
      "Formats and stages are ready.\n"
     ]
    }
   ],
   "source": [
    "# Ensure file formats & stages exist\n",
    "ensure_formats_and_stages(S)\n",
    "print(\"Formats and stages are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e3075",
   "metadata": {},
   "source": [
    "## Files to be Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f94009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_1.pdf',\n",
       " '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_2.pdf',\n",
       " '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_3.pdf',\n",
       " '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_4.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input directory path and files to be processed\n",
    "input_folder = Path(os.getcwd()) / \"input_folder2\"\n",
    "file_exts = set(S.file_exts)\n",
    "files = sorted([str(p) for p in input_folder.iterdir() if p.suffix.lower() in file_exts])\n",
    "print(f\"Found {len(files)} files.\")\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94685159",
   "metadata": {},
   "source": [
    "# Import your Schema\n",
    "\n",
    "The well-defined schema is a critical part of use case success. Take some time to study the invoice schema in `invoice_schema.py` and review the documentation on [schema development](https://docs.landing.ai/ade/ade-extract-playground#start-a-schema).\n",
    "\n",
    "This schema was developed iteratively using the Visual Playground provided by LandingAI at [https://va.landing.ai/demo/doc-extraction](https://va.landing.ai/demo/doc-extraction). \n",
    "\n",
    "Schemas can be defined using `pydantic` or JSON syntax. This notebook uses a `pydantic` schema with one level of nesting. Consult the Agentic Document Extraction documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31c2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your Pydantic schema used by parse()\n",
    "# The schema is already imported in the first code cell, but is repeated here for clarity. \n",
    "\n",
    "from invoice_schema import InvoiceExtractionSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533913ae",
   "metadata": {},
   "source": [
    "# üê§ Canary Parse + Stage\n",
    "\n",
    "Before streaming all documents, we run a **\"canary\" document** through the full pipeline. This helps validate that:\n",
    "\n",
    "- ADE parsing works as expected on real data\n",
    "- Schema-to-row conversion is correct\n",
    "- Snowflake stages and COPY commands succeed\n",
    "\n",
    "üõ†Ô∏è This operation:\n",
    "1. Parses a single document using `InvoiceExtractionSchema`\n",
    "2. Builds main, line-item, and markdown rows\n",
    "3. Uploads results to Snowflake stages\n",
    "4. Inserts into all four target tables\n",
    "\n",
    "This allows us to validate the pipeline end-to-end (Agentic extraction ‚Üí Snowflake COPY) before processing many files. The rows(s) inserted into Snowflake are clearly marked _CANARY for easy removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d579f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: /Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_3.pdf\n",
      "CANARY_RUN_ID: 20250907T151355_a6e655_CANARY\n"
     ]
    }
   ],
   "source": [
    "# Select one file randonly and assign it a Run ID for the Canary Run\n",
    "one_file = random.choice(files)\n",
    "print(\"Selected:\", one_file)\n",
    "paths_str = [str(one_file)]\n",
    "\n",
    "CANARY_RUN_ID = (\n",
    "    datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%S\")+ \"_\"+ uuid.uuid4().hex[:6]+ \"_CANARY\")\n",
    "print(\"CANARY_RUN_ID:\", CANARY_RUN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b5bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:13:56\u001b[0m [info   \u001b[0m] \u001b[1mAPI key is valid.             \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:42)\n",
      "\u001b[2m2025-09-07 15:13:56\u001b[0m [info   \u001b[0m] \u001b[1mParsing 1 documents           \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:280)\n",
      "\u001b[2m2025-09-07 15:13:56\u001b[0m [info   \u001b[0m] \u001b[1mSplitting PDF: '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_3.pdf' into 0 parts under '/var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpwory84x8'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:13:56\u001b[0m [info   \u001b[0m] \u001b[1mCreated /var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpwory84x8/invoice_3_1.pdf\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:252)\n",
      "\u001b[2m2025-09-07 15:13:56\u001b[0m [info   \u001b[0m] \u001b[1mStart parsing document part: 'File name: invoice_3_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.va.landing.ai/v1/tools/agentic-document-analysis \"HTTP/1.1 200 OK\" (_client.py:1025)\n",
      "\u001b[2m2025-09-07 15:14:36\u001b[0m [info   \u001b[0m] \u001b[1mTime taken to successfully parse a document chunk: 39.75 seconds\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:823)\n",
      "\u001b[2m2025-09-07 15:14:36\u001b[0m [info   \u001b[0m] \u001b[1mSuccessfully parsed document part: 'File name: invoice_3_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing document parts from 'invoice_3.pdf': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:39<00:00, 39.78s/it]\n",
      "Parsing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:39<00:00, 39.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed markdown: True | chunks: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Send the selected file for parsing and extraction (no Snowflke insertion yet)\n",
    "# See https://docs.landing.ai/ade/ade-parse-docs\n",
    "\n",
    "sent_at = datetime.now(timezone.utc)\n",
    "agentic_version = get_installed_version(\"agentic-doc\") \n",
    "\n",
    "# üß≠ Step 1: Parse the document using the schema and track time\n",
    "results = parse(paths_str, extraction_model=InvoiceExtractionSchema)\n",
    "doc = results[0]\n",
    "\n",
    "# agentic-doc outputs\n",
    "markdown = getattr(doc, \"markdown\", None)\n",
    "chunks   = getattr(doc, \"chunks\", None) or []\n",
    "f        = getattr(doc, \"extraction\", None)\n",
    "m        = getattr(doc, \"extraction_metadata\", None)\n",
    "\n",
    "print(\"Parsed markdown:\", isinstance(markdown, str), \"| chunks:\", len(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8227f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoice_info=DocumentInfo(invoice_date_raw='10/03/2022', invoice_date=datetime.date(2022, 10, 3), invoice_number='52255', order_date=None, po_number=None, status=None) customer_info=CustomerInfo(sold_to_name='Leo Vincent', sold_to_address='1000 Sarah Dr\\nSummerfield, NC  27358 USA', customer_email=None) company_info=SupplierInfo(supplier_name='CUSTOM ELECTRIC & PLUMBING, INC.', supplier_address='PO Box 533\\nSummerfield, NC  27358', representative='Mathew', email='Mat@CustomEandP.com', phone='336.701.5589', gstin=None, pan=None) order_details=TermsAndShipping(payment_terms='by Cash or Check, All sales final. $750.00 deposit at acceptance of contract balance due upon substantial completion of work. Agreement to include conditions of agreement addendum Clarifications: It is agreed that during the performance of the work drywall will/may be cut at the discretion of the contractor, this quotation does not include any drywall or painting repair or touchup. Parking to be provided onsite for all working personnel. Work will be completed during normal hours from 8:00 AM to 5:00 PM Monday thru Friday, unless approved otherwise. No additional components will be installed outside the scope of work enclosed. All fixtures and lamps are to be furnished on-site by others. Excluded from Bid: Repairs or corrections to existing plumbing, gas, or electrical system deficiencies or code violations. Repairs to any underground utilities (such as sprinkler lines, electrical lines, cable, etc.) not located and clearly marked prior to arrival on-site. Engineered drawings Utility power consumption.', ship_via=None, ship_date=None, tracking_number=None) totals_summary=TotalsSummary(currency=None, total_due_raw='$1,550.00', total_due=1550.0, subtotal=1550.0, tax=0.0, shipping=None, handling_fee=None) line_items=[LineItem(line_number=None, sku=None, description='Provide and install new 60 Amp 240Vac breaker and 6/2 Copper SE cable feeding new Tesla Wall connector. Install new customer supplied Tesla wall connector. Note: drywall may need to be cut to facilitate work. No drywall repairs or painting are included in this quote.', quantity=1.0, unit_price=1400.0, price=None, amount=1400.0, total=None), LineItem(line_number=None, sku=None, description='Permit and inspection fees', quantity=1.0, unit_price=150.0, price=None, amount=150.0, total=None), LineItem(line_number=None, sku=None, description='Payment Terms: by Cash or Check, All sales final. $750.00 deposit at acceptance of contract balance due upon substantial completion of work. Agreement to include conditions of agreement addendum Clarifications: It is agreed that during the performance of the work drywall will/may be cut at the discretion of the contractor, this quotation does not include any drywall or painting repair or touchup. Parking to be provided onsite for all working personnel. Work will be completed during normal hours from 8:00 AM to 5:00 PM Monday thru Friday, unless approved otherwise. No additional components will be installed outside the scope of work enclosed. All fixtures and lamps are to be furnished on-site by others. Excluded from Bid: Repairs or corrections to existing plumbing, gas, or electrical system deficiencies or code violations. Repairs to any underground utilities (such as sprinkler lines, electrical lines, cable, etc.) not located and clearly marked prior to arrival on-site. Engineered drawings Utility power consumption.', quantity=1.0, unit_price=0.0, price=None, amount=0.0, total=None)]\n",
      "invoice_info=DocumentInfoMetadata(invoice_date_raw=MetadataType[str](value='10/03/2022', chunk_references=['ee7fac7d-e3bf-4886-8aa1-be29196ce007'], confidence=0.999998852758698), invoice_date=MetadataType[date](value=datetime.date(2022, 10, 3), chunk_references=['ee7fac7d-e3bf-4886-8aa1-be29196ce007'], confidence=None), invoice_number=MetadataType[str](value='52255', chunk_references=['ee7fac7d-e3bf-4886-8aa1-be29196ce007'], confidence=0.9959265947023431), order_date=MetadataType[str](value=None, chunk_references=[], confidence=None), po_number=MetadataType[str](value=None, chunk_references=[], confidence=None), status=MetadataType[str](value=None, chunk_references=[], confidence=None)) customer_info=CustomerInfoMetadata(sold_to_name=MetadataType[str](value='Leo Vincent', chunk_references=['92a39832-aa99-4657-adc0-743b1c827712'], confidence=1.0), sold_to_address=MetadataType[str](value='1000 Sarah Dr\\nSummerfield, NC  27358 USA', chunk_references=['92a39832-aa99-4657-adc0-743b1c827712'], confidence=0.9994747016291954), customer_email=MetadataType[str](value=None, chunk_references=[], confidence=None)) company_info=SupplierInfoMetadata(supplier_name=MetadataType[str](value='CUSTOM ELECTRIC & PLUMBING, INC.', chunk_references=['5aadeb79-a1df-4501-9176-8bc89e9f2b46'], confidence=0.9626343067749213), supplier_address=MetadataType[str](value='PO Box 533\\nSummerfield, NC  27358', chunk_references=['5aadeb79-a1df-4501-9176-8bc89e9f2b46'], confidence=0.9599293910242418), representative=MetadataType[str](value='Mathew', chunk_references=['9bb16648-5fac-4e92-bda9-b262783a7ef8'], confidence=1.0), email=MetadataType[str](value='Mat@CustomEandP.com', chunk_references=['5aadeb79-a1df-4501-9176-8bc89e9f2b46'], confidence=0.9997890168380901), phone=MetadataType[str](value='336.701.5589', chunk_references=['5aadeb79-a1df-4501-9176-8bc89e9f2b46'], confidence=1.0), gstin=MetadataType[str](value=None, chunk_references=[], confidence=None), pan=MetadataType[str](value=None, chunk_references=[], confidence=None)) order_details=TermsAndShippingMetadata(payment_terms=MetadataType[str](value='by Cash or Check, All sales final. $750.00 deposit at acceptance of contract balance due upon substantial completion of work. Agreement to include conditions of agreement addendum Clarifications: It is agreed that during the performance of the work drywall will/may be cut at the discretion of the contractor, this quotation does not include any drywall or painting repair or touchup. Parking to be provided onsite for all working personnel. Work will be completed during normal hours from 8:00 AM to 5:00 PM Monday thru Friday, unless approved otherwise. No additional components will be installed outside the scope of work enclosed. All fixtures and lamps are to be furnished on-site by others. Excluded from Bid: Repairs or corrections to existing plumbing, gas, or electrical system deficiencies or code violations. Repairs to any underground utilities (such as sprinkler lines, electrical lines, cable, etc.) not located and clearly marked prior to arrival on-site. Engineered drawings Utility power consumption.', chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), ship_via=MetadataType[str](value=None, chunk_references=[], confidence=None), ship_date=MetadataType[str](value=None, chunk_references=[], confidence=None), tracking_number=MetadataType[str](value=None, chunk_references=[], confidence=None)) totals_summary=TotalsSummaryMetadata(currency=MetadataType[str](value=None, chunk_references=[], confidence=None), total_due_raw=MetadataType[str](value='$1,550.00', chunk_references=['6de07ea1-f0e0-4a2a-9fa1-1af8a41252bd'], confidence=None), total_due=MetadataType[float](value=1550.0, chunk_references=['6de07ea1-f0e0-4a2a-9fa1-1af8a41252bd'], confidence=None), subtotal=MetadataType[float](value=1550.0, chunk_references=['6de07ea1-f0e0-4a2a-9fa1-1af8a41252bd'], confidence=None), tax=MetadataType[float](value=0.0, chunk_references=['6de07ea1-f0e0-4a2a-9fa1-1af8a41252bd'], confidence=None), shipping=MetadataType[float](value=None, chunk_references=[], confidence=None), handling_fee=MetadataType[float](value=None, chunk_references=[], confidence=None)) line_items=[LineItemMetadata(line_number=MetadataType[str](value=None, chunk_references=[], confidence=None), sku=MetadataType[str](value=None, chunk_references=[], confidence=None), description=MetadataType[str](value='Provide and install new 60 Amp 240Vac breaker and 6/2 Copper SE cable feeding new Tesla Wall connector. Install new customer supplied Tesla wall connector. Note: drywall may need to be cut to facilitate work. No drywall repairs or painting are included in this quote.', chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), quantity=MetadataType[float](value=1.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), unit_price=MetadataType[float](value=1400.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), price=MetadataType[float](value=None, chunk_references=[], confidence=None), amount=MetadataType[float](value=1400.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), total=MetadataType[float](value=None, chunk_references=[], confidence=None)), LineItemMetadata(line_number=MetadataType[str](value=None, chunk_references=[], confidence=None), sku=MetadataType[str](value=None, chunk_references=[], confidence=None), description=MetadataType[str](value='Permit and inspection fees', chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), quantity=MetadataType[float](value=1.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), unit_price=MetadataType[float](value=150.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), price=MetadataType[float](value=None, chunk_references=[], confidence=None), amount=MetadataType[float](value=150.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), total=MetadataType[float](value=None, chunk_references=[], confidence=None)), LineItemMetadata(line_number=MetadataType[str](value=None, chunk_references=[], confidence=None), sku=MetadataType[str](value=None, chunk_references=[], confidence=None), description=MetadataType[str](value='Payment Terms: by Cash or Check, All sales final. $750.00 deposit at acceptance of contract balance due upon substantial completion of work. Agreement to include conditions of agreement addendum Clarifications: It is agreed that during the performance of the work drywall will/may be cut at the discretion of the contractor, this quotation does not include any drywall or painting repair or touchup. Parking to be provided onsite for all working personnel. Work will be completed during normal hours from 8:00 AM to 5:00 PM Monday thru Friday, unless approved otherwise. No additional components will be installed outside the scope of work enclosed. All fixtures and lamps are to be furnished on-site by others. Excluded from Bid: Repairs or corrections to existing plumbing, gas, or electrical system deficiencies or code violations. Repairs to any underground utilities (such as sprinkler lines, electrical lines, cable, etc.) not located and clearly marked prior to arrival on-site. Engineered drawings Utility power consumption.', chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), quantity=MetadataType[float](value=1.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), unit_price=MetadataType[float](value=0.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), price=MetadataType[float](value=None, chunk_references=[], confidence=None), amount=MetadataType[float](value=0.0, chunk_references=['6ac40f26-45b1-4923-95c8-a47836e21cb3'], confidence=None), total=MetadataType[float](value=None, chunk_references=[], confidence=None))]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the extracted fields and associated metadata\n",
    "print(f)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9990bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Connector for Python Version: 3.17.2, Python Version: 3.12.11, Platform: macOS-15.5-arm64-arm-64bit (connection.py:521)\n",
      "Connecting to GLOBAL Snowflake domain (connection.py:1464)\n",
      "Snowflake Connector for Python Version: 3.17.2, Python Version: 3.12.11, Platform: macOS-15.5-arm64-arm-64bit (connection.py:521)\n",
      "Connecting to GLOBAL Snowflake domain (connection.py:1464)\n",
      "COPY complete ‚Äî rows: main=1, lines=3, chunks=8, markdown=1\n"
     ]
    }
   ],
   "source": [
    "# Perform the Snowflake insertions for the one processed document\n",
    "# Query the four target Snowflake tables using the `run_id` to verify that rows were copied successfully.\n",
    "# If counts are zero or inconsistent, review earlier steps for parsing or staging issues.\n",
    "\n",
    "# üß≠ Step 2: Build all output rows from the document\n",
    "main_row, line_rows, chunk_rows, markdown_record, _uuid = rows_from_doc(\n",
    "    fp=str(one_file), doc=doc, run_id=CANARY_RUN_ID, sent_at=sent_at, agentic_version=agentic_version\n",
    ")\n",
    "\n",
    "# üß≠ Step 3: Add rows to loader for staging ‚Üí Snowflake COPY\n",
    "loader = Loader(CANARY_RUN_ID, S, cols_main=COLS_MAIN, cols_lines=COLS_LINES)\n",
    "\n",
    "if main_row: loader.add_main(main_row)\n",
    "for r in (line_rows or []): loader.add_line(r)\n",
    "for r in (chunk_rows or []): loader.add_chunk(r)\n",
    "if markdown_record: loader.add_markdown(markdown_record)\n",
    "\n",
    "# üß≠ Step 4: Upload the original file to the raw stage (optional archival)\n",
    "put_original_to_raw_stage(str(one_file), S, loader.conn)\n",
    "\n",
    "# üß≠ Step 5: Force a final flush and COPY (even with 1 file)\n",
    "loader.close()\n",
    "\n",
    "# üß≠ Step 6: Run SELECT COUNT(*) queries for this run_id\n",
    "with sfcursor(settings=S) as cur:\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {fq_table(S, S.table_main)} WHERE run_id=%s\", (CANARY_RUN_ID,))\n",
    "    main_ct = cur.fetchone()[0]\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {fq_table(S, S.table_lines)} WHERE run_id=%s\", (CANARY_RUN_ID,))\n",
    "    lines_ct = cur.fetchone()[0]\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {fq_table(S, S.table_chunks)} WHERE run_id=%s\", (CANARY_RUN_ID,))\n",
    "    chunks_ct = cur.fetchone()[0]\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {fq_table(S, S.table_markdown)} WHERE run_id=%s\", (CANARY_RUN_ID,))\n",
    "    md_ct = cur.fetchone()[0]\n",
    "\n",
    "print(f\"COPY complete ‚Äî rows: main={main_ct}, lines={lines_ct}, chunks={chunks_ct}, markdown={md_ct}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6094194",
   "metadata": {},
   "source": [
    "## üöÄ Streaming Document Processing with Metrics\n",
    "\n",
    "This cell runs the full pipeline over **all files** in the input folder.\n",
    "\n",
    "For each document, it:\n",
    "1. Parses the file using your schema\n",
    "2. Builds rows for multiple tables\n",
    "3. Uploads CSVs/JSON to Snowflake stage\n",
    "4. Performs `COPY INTO` for atomic insertion\n",
    "5. Captures timing and success/failure counts.\n",
    "\n",
    "\n",
    "### Parse and Extract Portion of the Pipeline\n",
    "The `agentic-doc` python libray will start work on 50 **documents** simultaneously due to BATCH_SIZE=50 in the `.env` file. Each document has MAX_WORKERS=2 associated with it. This means that within each document, up to 2 **pages** are processed in parallel. \n",
    "\n",
    "These settings work well with invoices because the majority are a single page and very few are more than 4 pages. Adjust the settings and check the timings based on your use case.\n",
    "\n",
    "### Snowflake Insertion Portion of the Pipeline\n",
    "As results from parse() come back, a per-file concurrent pipeline builds rows, stages shards and copies into tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5f69c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Connector for Python Version: 3.17.2, Python Version: 3.12.11, Platform: macOS-15.5-arm64-arm-64bit (connection.py:521)\n",
      "Connecting to GLOBAL Snowflake domain (connection.py:1464)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mAPI key is valid.             \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:42)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mAPI key is valid.             \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:42)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mParsing 1 documents           \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:280)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mAPI key is valid.             \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:42)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mParsing 1 documents           \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mAPI key is valid.             \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:42)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mParsing 1 documents           \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:280)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mParsing 1 documents           \u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mSplitting PDF: '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_1.pdf' into 0 parts under '/var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpn9_2mc4a'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mCreated /var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpn9_2mc4a/invoice_1_1.pdf\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:252)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Parsing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mSplitting PDF: '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_3.pdf' into 0 parts under '/var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpvdd752cj'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mStart parsing document part: 'File name: invoice_1_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:670)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mCreated /var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpvdd752cj/invoice_3_1.pdf\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:252)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mSplitting PDF: '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_4.pdf' into 0 parts under '/var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpc_usu2w0'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing document parts from 'invoice_1.pdf':   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mSplitting PDF: '/Users/andreakropp/Documents/Demos/ADE Demos/Notebooks/Snowflake_Insertion_Demo/input_folder2/invoice_2.pdf' into 0 parts under '/var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmp68r1e1f3'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:236)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mStart parsing document part: 'File name: invoice_3_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:670)\n",
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mCreated /var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmpc_usu2w0/invoice_4_1.pdf\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:252)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mCreated /var/folders/wn/5bkqt1cs3x9_tn9h8nbwfpnm0000gn/T/tmp68r1e1f3/invoice_2_1.pdf\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.utils\u001b[0m]\u001b[0m (utils.py:252)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing document parts from 'invoice_3.pdf':   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mStart parsing document part: 'File name: invoice_4_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-07 15:14:48\u001b[0m [info   \u001b[0m] \u001b[1mStart parsing document part: 'File name: invoice_2_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.va.landing.ai/v1/tools/agentic-document-analysis \"HTTP/1.1 200 OK\" (_client.py:1025)\n",
      "\u001b[2m2025-09-07 15:15:11\u001b[0m [info   \u001b[0m] \u001b[1mTime taken to successfully parse a document chunk: 22.57 seconds\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:823)\n",
      "\u001b[2m2025-09-07 15:15:11\u001b[0m [info   \u001b[0m] \u001b[1mSuccessfully parsed document part: 'File name: invoice_1_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Parsing document parts from 'invoice_1.pdf': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:22<00:00, 22.59s/it]\n",
      "Parsing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:22<00:00, 22.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.va.landing.ai/v1/tools/agentic-document-analysis \"HTTP/1.1 200 OK\" (_client.py:1025)\n",
      "\u001b[2m2025-09-07 15:15:16\u001b[0m [info   \u001b[0m] \u001b[1mTime taken to successfully parse a document chunk: 27.13 seconds\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:823)\n",
      "\u001b[2m2025-09-07 15:15:16\u001b[0m [info   \u001b[0m] \u001b[1mSuccessfully parsed document part: 'File name: invoice_2_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Parsing document parts from 'invoice_2.pdf': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:27<00:00, 27.14s/it]\n",
      "\n",
      "\n",
      "Parsing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:27<00:00, 27.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.va.landing.ai/v1/tools/agentic-document-analysis \"HTTP/1.1 200 OK\" (_client.py:1025)\n",
      "\u001b[2m2025-09-07 15:15:26\u001b[0m [info   \u001b[0m] \u001b[1mTime taken to successfully parse a document chunk: 37.37 seconds\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:823)\n",
      "\u001b[2m2025-09-07 15:15:26\u001b[0m [info   \u001b[0m] \u001b[1mSuccessfully parsed document part: 'File name: invoice_3_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Parsing document parts from 'invoice_3.pdf': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:37<00:00, 37.32s/it]\n",
      "Parsing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:37<00:00, 37.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.va.landing.ai/v1/tools/agentic-document-analysis \"HTTP/1.1 200 OK\" (_client.py:1025)\n",
      "\u001b[2m2025-09-07 15:15:28\u001b[0m [info   \u001b[0m] \u001b[1mTime taken to successfully parse a document chunk: 39.37 seconds\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:823)\n",
      "\u001b[2m2025-09-07 15:15:28\u001b[0m [info   \u001b[0m] \u001b[1mSuccessfully parsed document part: 'File name: invoice_4_1.pdf\tPage: [0:0]'\u001b[0m [\u001b[0m\u001b[1m\u001b[34magentic_doc.parse\u001b[0m]\u001b[0m (parse.py:679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Parsing document parts from 'invoice_4.pdf': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:39<00:00, 39.38s/it]\n",
      "\n",
      "Parsing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:39<00:00, 39.48s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional: run a small subset first, e.g., files[:25]\n",
    "batch_streaming = files[:]  # or files[:25]\n",
    "\n",
    "metrics_streaming = run_pipeline_streaming(\n",
    "    batch_streaming,  # or a subset like files[:25]\n",
    "    schema_cls=InvoiceExtractionSchema,\n",
    "    rows_from_doc_fn=rows_from_doc,\n",
    "    settings=S,\n",
    "    cols_main=COLS_MAIN,\n",
    "    cols_lines=COLS_LINES,\n",
    "    # run_id_suffix=\"\",  # Optional to add your own suffix to the generated run_id\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318158c",
   "metadata": {},
   "source": [
    "## üìä Results Summary\n",
    "\n",
    "Final metrics show the overall performance of the pipeline run.\n",
    "\n",
    "Includes:\n",
    "- ‚úÖ Count of successfully parsed documents\n",
    "- ‚ùå Count of failures\n",
    "- üìÑ Total pages processed\n",
    "- ‚è±Ô∏è Wall-clock time and parse time\n",
    "- üìà Average time per document and per page\n",
    "\n",
    "Check the **wall time per document and per page**. The optimal settings will depend on your document mix. To really test the timing, we suggest a batch of documents that is 5X the BATCH_SIZE. In this case BATCH _SIZE=50, so testing with 250 invoices would best demonstrate how Agentic Document Extraction begin processing the next files upon successful completion of a prior file and Snowflake streaming insertion is continuous.\n",
    "\n",
    "The `parse()` from Agentic Document Extraction includes both parsing and field extraction in the timing. Longer documents and longer schemas require more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08acd158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 20250907T151447_5c7a95\n",
      "Files: 4 OK / 0 failed / 4 total\n",
      "Pages: 4\n",
      "\n",
      "Total times (seconds):\n",
      "  Wall clock:   47.58\n",
      "  Parse:        129.07\n",
      "  COPY:         7.51\n",
      "\n",
      "Avg time per PAGE (s):\n",
      "  Parse:        32.267\n",
      "  Pipeline:     34.146\n",
      "  Wall clock:   11.895\n",
      "\n",
      "Avg time per DOC (s):\n",
      "  Parse:        32.267\n",
      "  Pipeline:     34.146\n",
      "  Wall clock:   11.895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_streaming.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb622443",
   "metadata": {},
   "source": [
    "## üßæ Conclusions & Support\n",
    "\n",
    "This notebook provides a working reference for using ADE with Snowflake to parse, transform, and persist structured data from documents like invoices.\n",
    "\n",
    "Because it is modular, it can be easily adapted to other document types ‚Äî simply update:\n",
    "- The schema (e.g., PO, receipts, resumes)\n",
    "- The `rows_from_doc()` logic\n",
    "- The Snowflake table structure\n",
    "\n",
    "### üí¨ Need Help?\n",
    "\n",
    "üìö [Documentation](https://docs.landing.ai/ade/ade-overview)  \n",
    "üëæ [Discord Support Server](https://docs.landing.ai/ade/ade-support#discord-channel)  \n",
    "üì• Submit a ticket or talk to the bot on Discord.\n",
    "\n",
    "We‚Äôre here to help!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
